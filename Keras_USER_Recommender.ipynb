{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_path = \"./DataSets/\"\n",
    "Movies_metadata = pd.read_csv(Dataset_path+\"MoviesInfo.csv\")\n",
    "ratings = pd.read_csv(Dataset_path+\"ml-latest/ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### just keep rating year between 1995, 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# strftime('%Y-%m-%d %H:%M:%S')\n",
    "ratings['year_rated'] = ratings['timestamp'].apply(lambda x: int( datetime.fromtimestamp( x ).strftime('%Y') ) )\n",
    "\n",
    "ratings = ratings[ ratings['year_rated'].between(1995, 2001)].copy()\n",
    "\n",
    "ratings.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Ratings : 7329482\n",
      "number of movies : 4937\n",
      "number of users : 103827\n",
      "range of rating : ( 1.0, 5.0)  \n"
     ]
    }
   ],
   "source": [
    "print( f\"number of Ratings : { ratings.shape[0] }\")\n",
    "print( f\"number of movies : { ratings.groupby('movieId').count().shape[0] }\")\n",
    "print( f\"number of users : { ratings.groupby('userId').count().shape[0] }\")\n",
    "print( f\"range of rating : ( { np.min( ratings.groupby('rating').count().index )}, {np.max( ratings.groupby('rating').count().index )})  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyCol = ['movieId','year','duration','metascore','reviews_from_users','reviews_from_critics'\n",
    "         ,'country','language','director','production_company','mean_vote']\n",
    "FinalDataset = pd.merge(ratings, Movies_metadata[ MyCol ], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7206877 entries, 0 to 7206876\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   userId                int64  \n",
      " 1   movieId               int64  \n",
      " 2   rating                float64\n",
      " 3   timestamp             int64  \n",
      " 4   year_rated            int64  \n",
      " 5   year                  int64  \n",
      " 6   duration              int64  \n",
      " 7   metascore             float64\n",
      " 8   reviews_from_users    float64\n",
      " 9   reviews_from_critics  float64\n",
      " 10  country               object \n",
      " 11  language              object \n",
      " 12  director              object \n",
      " 13  production_company    object \n",
      " 14  mean_vote             float64\n",
      "dtypes: float64(5), int64(6), object(4)\n",
      "memory usage: 879.7+ MB\n"
     ]
    }
   ],
   "source": [
    "FinalDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7206877 entries, 0 to 7206876\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   userId                int64  \n",
      " 1   movieId               int64  \n",
      " 2   rating                float64\n",
      " 3   timestamp             int64  \n",
      " 4   year_rated            int64  \n",
      " 5   year                  int64  \n",
      " 6   duration              int64  \n",
      " 7   metascore             float64\n",
      " 8   reviews_from_users    float64\n",
      " 9   reviews_from_critics  float64\n",
      " 10  country               int16  \n",
      " 11  language              int16  \n",
      " 12  director              int16  \n",
      " 13  production_company    int16  \n",
      " 14  mean_vote             float64\n",
      "dtypes: float64(5), int16(4), int64(6)\n",
      "memory usage: 714.8 MB\n"
     ]
    }
   ],
   "source": [
    "myobj = ['country','language','director','production_company']\n",
    "obj_FinalDataset= FinalDataset.select_dtypes(include=['object']).copy()\n",
    "\n",
    "for i in myobj:\n",
    "    obj_FinalDataset[i] = obj_FinalDataset[i].astype('category')\n",
    "    FinalDataset[i] = obj_FinalDataset[i].cat.codes\n",
    "    \n",
    "FinalDataset = FinalDataset.fillna(100000)\n",
    "FinalDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  FinalDataset[['userId' ,'movieId','year','duration','metascore','reviews_from_users','reviews_from_critics'\n",
    "                              ,'country','language','director','production_company','mean_vote','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6578912 entries, 0 to 7206874\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   year                  float64\n",
      " 1   duration              float64\n",
      " 2   metascore             float64\n",
      " 3   reviews_from_users    float64\n",
      " 4   reviews_from_critics  float64\n",
      " 5   country               float64\n",
      " 6   language              float64\n",
      " 7   director              float64\n",
      " 8   production_company    float64\n",
      " 9   mean_vote             float64\n",
      " 10  userId                int64  \n",
      " 11  movieId               int64  \n",
      " 12  rating                float64\n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 702.7 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(data.drop(['movieId','userId','rating'],axis=1))\n",
    "data_norm = pd.DataFrame(scaled,columns=(data.drop(['movieId','userId','rating'],axis=1).columns))\n",
    "data_norm= data_norm.join(data['userId'])\n",
    "data_norm= data_norm.join(data['movieId'])\n",
    "data_norm= data_norm.join(data['rating'])\n",
    "\n",
    "                               \n",
    "from scipy import stats\n",
    "z_scores = stats.zscore(data_norm.drop(['movieId','mean_vote'],axis=1))\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "newdata = data_norm[filtered_entries]\n",
    "\n",
    "newdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = newdata['rating'] \n",
    "predictors = newdata.drop(['userId','movieId','rating'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.30, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model01 = Sequential()\n",
    "model01.add(Dense(200, activation='relu', input_dim=10))\n",
    "model01.add(Dense(100, activation='relu'))\n",
    "model01.add(Dense(50, activation='relu'))\n",
    "model01.add(Dense(25, activation='relu'))\n",
    "model01.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model01.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 76838/460524 [====>.........................] - ETA: 14:10 - loss: 0.7705 - mean_squared_error: 1.0340"
     ]
    }
   ],
   "source": [
    "model01.fit(X_train, y_train, epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
