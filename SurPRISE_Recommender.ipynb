{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-dallas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "destroyed-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "# Imports\n",
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import wordcloud as wc\n",
    "import scipy.sparse as sparse\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import jenkspy\n",
    "import statsmodels.tools.tools as stattools\n",
    "from itertools import combinations\n",
    "\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import surprise\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering, accuracy  \n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tested-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "young-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB :\n",
    "  Dataset_path = \"/content/drive/MyDrive/Colab Notebooks/DataSets/\"\n",
    "else :\n",
    "  Dataset_path = \"./DataSets/\"\n",
    "\n",
    "ml_path = Dataset_path + \"ml-latest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infrared-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv( ml_path + \"ratings.csv\")\n",
    "\n",
    "Movies_metadata = pd.read_csv(Dataset_path+\"MoviesInfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "little-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27753444 entries, 0 to 27753443\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 847.0 MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-possibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-positive",
   "metadata": {},
   "source": [
    "### just keep rating year between 1995, 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "underlying-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# strftime('%Y-%m-%d %H:%M:%S')\n",
    "ratings['year_rated'] = ratings['timestamp'].apply(lambda x: int( datetime.fromtimestamp( x ).strftime('%Y') ) )\n",
    "\n",
    "ratings = ratings[ ratings['year_rated'].between(1995, 2001)].copy()\n",
    "\n",
    "ratings.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stopped-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Ratings : 7329482\n",
      "number of movies : 4937\n",
      "number of users : 103827\n",
      "range of rating : ( 1.0, 5.0)  \n"
     ]
    }
   ],
   "source": [
    "print( f\"number of Ratings : { ratings.shape[0] }\")\n",
    "print( f\"number of movies : { ratings.groupby('movieId').count().shape[0] }\")\n",
    "print( f\"number of users : { ratings.groupby('userId').count().shape[0] }\")\n",
    "print( f\"range of rating : ( { np.min( ratings.groupby('rating').count().index )}, {np.max( ratings.groupby('rating').count().index )})  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-salon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "numeric-performance",
   "metadata": {},
   "source": [
    "### just keep rating that user and movie are upper than threshhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "racial-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data frame shape:\t(7329482, 5)\n",
      "The new data frame shape:\t(6921125, 5)\n"
     ]
    }
   ],
   "source": [
    "min_movie_ratings = 20\n",
    "filter_Movies = ratings['movieId'].value_counts() > min_movie_ratings\n",
    "filter_Movies = filter_Movies[filter_Movies].index.tolist()\n",
    "\n",
    "min_user_ratings = 20\n",
    "filter_users = ratings['userId'].value_counts() > min_user_ratings\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "df_new = ratings[(ratings['movieId'].isin(filter_Movies)) & (ratings['userId'].isin(filter_users))]\n",
    "print('The original data frame shape:\\t{}'.format(ratings.shape))\n",
    "print('The new data frame shape:\\t{}'.format(df_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-helping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of movies : 4393\n",
      "number of users : 64140\n",
      "range of rating : ( 1.0, 5.0)  \n"
     ]
    }
   ],
   "source": [
    "print( f\"number of movies : { df_new.groupby('movieId').count().shape[0] }\")\n",
    "print( f\"number of users : { df_new.groupby('userId').count().shape[0] }\")\n",
    "print( f\"range of rating : ( { np.min( df_new.groupby('rating').count().index )}, {np.max( df_new.groupby('rating').count().index )})  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-dating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hundred-price",
   "metadata": {},
   "source": [
    "## initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "crucial-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1., 5.))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-count",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-intention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-width",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-messenger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bronze-passion",
   "metadata": {},
   "source": [
    "### User-user Collaborative Filtering\n",
    "https://surprise.readthedocs.io/en/stable/knn_inspired.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use user_based true/false to switch between user-based or item-based collaborative filtering\n",
    "algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now query for specific predicions\n",
    "uid = str(10)  # raw user id\n",
    "iid = str(10)  # raw item id\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the trained model against the testset\n",
    "# get RMSE\n",
    "print(\"User-based Model : Test Set\")\n",
    "test_pred = algo.test(testset)\n",
    "accuracy.rmse(test_pred, verbose=True)\n",
    "\n",
    "# if you wanted to evaluate on the trainset\n",
    "print(\"User-based Model : Training Set\")\n",
    "train_pred = algo.test(trainset.build_testset())\n",
    "accuracy.rmse(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-consolidation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "applied-spare",
   "metadata": {},
   "source": [
    "### Item-Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use user_based true/false to switch between user-based or item-based collaborative filtering\n",
    "algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the trained model against the testset\n",
    "# get RMSE\n",
    "print(\"Item-based Model : Test Set\")\n",
    "test_pred = algo.test(testset)\n",
    "accuracy.rmse(test_pred, verbose=True)\n",
    "\n",
    "# if you wanted to evaluate on the trainset\n",
    "print(\"Item-based Model : Training Set\")\n",
    "train_pred = algo.test(trainset.build_testset())\n",
    "accuracy.rmse(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-height",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "covered-shanghai",
   "metadata": {},
   "source": [
    "### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —– SVD —– #\n",
    "\n",
    "param_grid = {'n_factors': [110, 120, 140, 160], \n",
    "              'n_epochs': [90, 100, 110], \n",
    "              'lr_all': [0.001, 0.003, 0.005, 0.008],\n",
    "              'reg_all': [0.08, 0.1, 0.15] }\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "algo = gs.best_estimator['rmse']\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-supplement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-therapist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the new parameters with the train data\n",
    "svd = SVD(n_factors=160, n_epochs=100, lr_all=0.005, reg_all=0.1)\n",
    "svd.fit(trainset)\n",
    "test_pred = svd.test(testset)\n",
    "print(\"SVD : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-desert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import random\n",
    "\n",
    "def get_Movie_info(Movie_id, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns some basic information about a Movie given the Movie id and the metadata dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    Movie_info = metadata[metadata['movieId'] == Movie_id][['movieId', 'genres', \n",
    "                                                            'title', 'original_title', 'year', 'duration']]\n",
    "    return Movie_info.to_dict(orient='records')\n",
    "\n",
    "def generate_recommendation(user_id, model, metadata, thresh=4):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a Movie recommendation for a user based on a rating threshold. Only\n",
    "    Movies with a predicted rating at or above the threshold will be recommended\n",
    "    \"\"\"\n",
    "    \n",
    "    Movies_ID = ratings.movieId.unique().tolist()\n",
    "    random.shuffle(Movies_ID)\n",
    "    \n",
    "    for Movie_ID in Movies_ID:\n",
    "        rating = model.predict(uid=user_id, iid=Movie_ID).est\n",
    "        if rating >= thresh:\n",
    "            return get_Movie_info(Movie_ID, metadata) , rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_recommendation(51737, svd, Movies_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-spiritual",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, n_iter=500, verbose=3, random_state=1)\n",
    "\n",
    "Movies_embedding = tsne.fit_transform(svd.qi)\n",
    "\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=Movies_embedding)\n",
    "\n",
    "projection['title'] = Movies_metadata['original_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datapane as dp\n",
    "\n",
    "def plot_Movies(Movies_ID, plot_name):\n",
    "    \n",
    "    Movie_indices = []\n",
    "    for Movie in Movies_ID:\n",
    "        Movie_indices.append( Movies_ID.index(Movie) )\n",
    "        \n",
    "    Movies_vector_df = projection.iloc[ Movie_indices ]\n",
    "    \n",
    "    fig = px.scatter(\n",
    "    Movies_vector_df, x='x', y='y', text='title',\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies_ID = ratings.movieId.unique().tolist()\n",
    "\n",
    "plot_Movies(Movies_ID, plot_name='Movies_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-complexity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FDM2021",
   "language": "python",
   "name": ".fdm2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
